<!doctype html><html lang=en-us dir=auto><head><meta name=generator content="Hugo 0.145.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Notes</title>
<meta name=description content><meta name=author content><link rel=canonical href=https://HowardHsuuu.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=icon type=image/png sizes=16x16 href=https://HowardHsuuu.github.io/images/icon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://HowardHsuuu.github.io/images/icon-32x32.png><link rel=apple-touch-icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=mask-icon href=https://HowardHsuuu.github.io/images/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://HowardHsuuu.github.io/index.xml><link rel=alternate hreflang=en-us href=https://HowardHsuuu.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-...some_hash... crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="Notes"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://HowardHsuuu.github.io/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Notes"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Notes","url":"https://HowardHsuuu.github.io/","description":"","thumbnailUrl":"https://HowardHsuuu.github.io/images/icon.png","sameAs":["https://github.com/HowardHsuuu"]}</script></head><body class="list dark" id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://HowardHsuuu.github.io/ accesskey=h title="Notes (Alt + H)"><img src=https://HowardHsuuu.github.io/images/icon.png alt aria-label=logo height=35>Notes</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://HowardHsuuu.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://HowardHsuuu.github.io/posts/ title=Topics><span>Topics</span></a></li><li><a href=https://HowardHsuuu.github.io/tags title=Tags><span>Tags</span></a></li><li><a href=https://HowardHsuuu.github.io/aboutme/ title="About Me"><span>About Me</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] Unveiling Theory of Mind in LLMs</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
Paper Info
arXiv:2309.01660
Title: Unveiling Theory of Mind in Large Language Models: A Parallel to Single Neurons in the Human Brain
Author: Mohsen Jamali and Ziv M. Williams and Jing Cai
Prior Knowledge Theory of Mind (ToM): A complex cognitive capacity related to our conscious mind and mental state that allows us to infer another’s beliefs and perspective. Through ToM, human can create intricate mental representations of other agents and realize that others may have beliefs that’s different from our own or the objective reality. True- and False-belief Task True-belief task: assesses whether someone understands that some other people’s believes is correctly aligned with reality. False-belief task: assesses whether someone understands that some other people’s believes is not correctly aligned with reality. (ex: belief diverges from reality after a change to the environment that one did not witness.) A critical test for ToM is the false belief task. Both tasks are evaluated by providing the participant a scenario and asking the participant “fact questions” and “belief questions”, which are about the reality and the belief of some character in the scenario respectively. These tasks are designed to test if the individual can attribute mental states (including potentially false beliefs) to others in general. ToM in the human brain Human brain imaging studies have provided substantial evidence for the brain network that supports our ToM ability, including the temporalparietal junction, superior temporal sulcus and the dorsal medial prefrontal cortex (dmPFC)
...</p></div><footer class=entry-footer><span title='2024-10-29 19:24:43 +0800 +0800'>October 29, 2024</span>&nbsp;·&nbsp;6 min</footer><a class=entry-link aria-label="post link to [LR] Unveiling Theory of Mind in LLMs" href=https://HowardHsuuu.github.io/posts/lr/llm-tom/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] Binocular Vision SSVEP BCI for Dual-Frequency Modulation</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
Paper Info
DOI: 10.1109/TBME.2022.3212192
Title: A Binocular Vision SSVEP Brain–Computer Interface Paradigm for Dual-Frequency Modulation
Authors: Yike Sun, Liyan Liang, Jingnan Sun, Xiaogang Chen, Runfa Tian, Yuanfang Chen, Lijian Zhang, and Xiaorong Gao
Prior Knowledge SSVEP and BCIs: Steady-State Visual Evoked Potentials (SSVEPs) are brain responses elicited by periodic visual stimuli. Their robustness and high signal-to-noise ratio make them a cornerstone in non-invasive BCI research Dual-Frequency Stimulation: Traditional dual-frequency paradigms, such as the checkerboard arrangement, allow the encoding of more targets but are hampered by intermodulation artifacts, which can compromise signal quality. Binocular Vision Approach: By using circularly polarized light to deliver different frequencies to each eye, the binocular vision paradigm minimizes interference from intermodulation harmonics, thereby enhancing signal fidelity. Goal To design and evaluate a novel dual-frequency SSVEP paradigm based on binocular vision that suppresses intermodulation harmonics and enhances overall BCI performance, particularly in training-free applications.
...</p></div><footer class=entry-footer><span title='2024-10-12 20:32:51 +0800 +0800'>October 12, 2024</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [LR] Binocular Vision SSVEP BCI for Dual-Frequency Modulation" href=https://HowardHsuuu.github.io/posts/lr/ssvep-bci/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] Clonemator: Spatiotemporal Clones in VR</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
[The VR project, ChronoClones, in OpenHCI 2024 was based on this paper]
Paper Info
arXiv: 2311.04427
Title: Clonemator: Composing Spatiotemporal Clones to Create Interactive Automators in Virtual Reality
Authors: Yi-Shuo Lin, Ching-Yi Tsai, Lung-Pan Cheng
Prior Knowledge Interaction Techniques in VR: Traditional approaches (e.g., Go-Go, portals) focus on specific tasks or single-avatar enhancements. While helpful, these designs rarely offer a broad, integrative way to handle diverse, complex interactions without pre-coded solutions. Programming by Demonstration (PbD): Non-VR automation tools like Sikuli or Ringer let users capture and replay interactions to automate tasks. However, applying PbD to immersive VR—where physical presence, body movement, and 3D spatial context matter—is underexplored. Goal Clonemator aims to let users create and collaborate with virtual “clones” of themselves to accomplish complex or repetitive tasks, all without manual scripting. By allowing clones to be configured across space (e.g., different locations, scales) and time (e.g., static pose, synchronous motion, or replayed actions), the system seeks to empower users to construct flexible, intuitive “automators” for tasks ranging from object manipulation to cooperative assemblies.
...</p></div><footer class=entry-footer><span title='2024-09-27 19:56:26 +0800 +0800'>September 27, 2024</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [LR] Clonemator: Spatiotemporal Clones in VR" href=https://HowardHsuuu.github.io/posts/lr/clonemator/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] Quixer: A Quantum Transformer Model</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
[Qiix at Qiskit Hackathon Taiwan 2024 was inspired by this paper]
Paper Info
arXiv: 2406.04305
Title: Quixer: A Quantum Transformer Model
Authors: Nikhil Khatri, Gabriel Matos, Luuk Coopmans, Stephen Clark (Quantinuum)
Prior Knowledge Linear Combination of Unitaries (LCU)
The LCU technique allows the combination of multiple unitary operators into one overall operator using additional control qubits and postselection. Given unitaries $U_0, U_1, \dots, U_{n-1}$ with complex coefficients $b_0, b_1, \dots, b_{n-1}$, one can effectively prepare a block-encoded operator $$ M = \sum_{j=0}^{n-1} b_j U_j. $$
...</p></div><footer class=entry-footer><span title='2024-09-27 19:56:26 +0800 +0800'>September 27, 2024</span>&nbsp;·&nbsp;4 min</footer><a class=entry-link aria-label="post link to [LR] Quixer: A Quantum Transformer Model" href=https://HowardHsuuu.github.io/posts/lr/quixer/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>OTSea Staking - lost 26k due to a logic flaw in their contract</h2></header><div class=entry-content><p>What happened Staking contract, OTSeaStaking, hacked and lost 26k. Hacker exploited the contract’s logic flaw, which allowed him/her to call “withdraw” many times and got a lot more tokens than he staked.
The problem In line 396 of OTSeaStaking.sol, you can see that deposit.amount is not handled properly (not decreased); therefore, one can deposit once and withdraw multiple times.
PoC The PoC of this incident I wrote can be found here
Reference transaction hash https://nickfranklin.site/2024/09/13/otsea-staking-hacked/</p></div><footer class=entry-footer><span title='2024-09-25 23:06:01 +0800 +0800'>September 25, 2024</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to OTSea Staking - lost 26k due to a logic flaw in their contract" href=https://HowardHsuuu.github.io/posts/defi/otsea-staking/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://HowardHsuuu.github.io/page/2/>«&nbsp;&nbsp;
</a><a class=next href=https://HowardHsuuu.github.io/page/4/>&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://HowardHsuuu.github.io/>Notes</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script type=text/javascript src=/js/canvas-nest.js count=80 color=102,255,178 opacity=1></script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>