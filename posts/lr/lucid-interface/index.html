<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[LR] Interfacing with Lucid Dreams | Notes</title>
<meta name=keywords content="Human-Computer Interaction"><meta name=description content="[This review is intended solely for my personal learning]
Paper Info - LuciEntry

DOI: 10.1145/3613905.3649123
Title: LuciEntry: A Modular Lab-based Lucid Dreaming Induction Prototype
Authors: Po-Yao (Cosmos) Wang, Nathaniel Lee Yung Xiang, Rohit Rajesh, Antony Smith Loose, Nathan Semertzidis, and Florian ‘Floyd’ Mueller
Paper Info - DreamCeption

DOI: 10.1145/3613905.3649121
Title: DreamCeption: Towards Understanding the Design of Targeted Lucid Dream Mediation
Authors: Po-Yao (Cosmos) Wang, Rohit Rajesh, Antony Smith Loose, Nathaniel Lee Yung Xiang, Nathalie Overdevest, Nathan Semertzidis, and Florian ‘Floyd’ Mueller"><meta name=author content><link rel=canonical href=https://HowardHsuuu.github.io/posts/lr/lucid-interface/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=icon type=image/png sizes=16x16 href=https://HowardHsuuu.github.io/images/icon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://HowardHsuuu.github.io/images/icon-32x32.png><link rel=apple-touch-icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=mask-icon href=https://HowardHsuuu.github.io/images/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://HowardHsuuu.github.io/posts/lr/lucid-interface/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-...some_hash... crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="[LR] Interfacing with Lucid Dreams"><meta property="og:description" content="[This review is intended solely for my personal learning]
Paper Info - LuciEntry

DOI: 10.1145/3613905.3649123
Title: LuciEntry: A Modular Lab-based Lucid Dreaming Induction Prototype
Authors: Po-Yao (Cosmos) Wang, Nathaniel Lee Yung Xiang, Rohit Rajesh, Antony Smith Loose, Nathan Semertzidis, and Florian ‘Floyd’ Mueller
Paper Info - DreamCeption

DOI: 10.1145/3613905.3649121
Title: DreamCeption: Towards Understanding the Design of Targeted Lucid Dream Mediation
Authors: Po-Yao (Cosmos) Wang, Rohit Rajesh, Antony Smith Loose, Nathaniel Lee Yung Xiang, Nathalie Overdevest, Nathan Semertzidis, and Florian ‘Floyd’ Mueller"><meta property="og:type" content="article"><meta property="og:url" content="https://HowardHsuuu.github.io/posts/lr/lucid-interface/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-25T20:33:52+08:00"><meta property="article:modified_time" content="2024-09-25T20:33:52+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[LR] Interfacing with Lucid Dreams"><meta name=twitter:description content="[This review is intended solely for my personal learning]
Paper Info - LuciEntry

DOI: 10.1145/3613905.3649123
Title: LuciEntry: A Modular Lab-based Lucid Dreaming Induction Prototype
Authors: Po-Yao (Cosmos) Wang, Nathaniel Lee Yung Xiang, Rohit Rajesh, Antony Smith Loose, Nathan Semertzidis, and Florian ‘Floyd’ Mueller
Paper Info - DreamCeption

DOI: 10.1145/3613905.3649121
Title: DreamCeption: Towards Understanding the Design of Targeted Lucid Dream Mediation
Authors: Po-Yao (Cosmos) Wang, Rohit Rajesh, Antony Smith Loose, Nathaniel Lee Yung Xiang, Nathalie Overdevest, Nathan Semertzidis, and Florian ‘Floyd’ Mueller"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Topics","item":"https://HowardHsuuu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Literature Review","item":"https://HowardHsuuu.github.io/posts/lr/"},{"@type":"ListItem","position":3,"name":"[LR] Interfacing with Lucid Dreams","item":"https://HowardHsuuu.github.io/posts/lr/lucid-interface/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[LR] Interfacing with Lucid Dreams","name":"[LR] Interfacing with Lucid Dreams","description":"[This review is intended solely for my personal learning]\nPaper Info - LuciEntry\nDOI: 10.1145/3613905.3649123\nTitle: LuciEntry: A Modular Lab-based Lucid Dreaming Induction Prototype\nAuthors: Po-Yao (Cosmos) Wang, Nathaniel Lee Yung Xiang, Rohit Rajesh, Antony Smith Loose, Nathan Semertzidis, and Florian ‘Floyd’ Mueller\nPaper Info - DreamCeption\nDOI: 10.1145/3613905.3649121\nTitle: DreamCeption: Towards Understanding the Design of Targeted Lucid Dream Mediation\nAuthors: Po-Yao (Cosmos) Wang, Rohit Rajesh, Antony Smith Loose, Nathaniel Lee Yung Xiang, Nathalie Overdevest, Nathan Semertzidis, and Florian ‘Floyd’ Mueller\n","keywords":["Human-Computer Interaction"],"articleBody":"[This review is intended solely for my personal learning]\nPaper Info - LuciEntry\nDOI: 10.1145/3613905.3649123\nTitle: LuciEntry: A Modular Lab-based Lucid Dreaming Induction Prototype\nAuthors: Po-Yao (Cosmos) Wang, Nathaniel Lee Yung Xiang, Rohit Rajesh, Antony Smith Loose, Nathan Semertzidis, and Florian ‘Floyd’ Mueller\nPaper Info - DreamCeption\nDOI: 10.1145/3613905.3649121\nTitle: DreamCeption: Towards Understanding the Design of Targeted Lucid Dream Mediation\nAuthors: Po-Yao (Cosmos) Wang, Rohit Rajesh, Antony Smith Loose, Nathaniel Lee Yung Xiang, Nathalie Overdevest, Nathan Semertzidis, and Florian ‘Floyd’ Mueller\nPrior Knowledge Lucid dreaming is a phenomenon wherein sleepers become aware of dreaming while asleep, often enabling manipulation of dream content and providing potential benefits such as enhanced creativity, nightmare alleviation, and stress relief. Past research has focused on techniques for lucid dream induction (e.g., wake-back-to-bed, mnemonic induction) and explored the use of interactive technologies—such as auditory or visual cues—to influence dream content. However, effectively automating or streamlining this process, as well as helping dreamers shape specific dream topics, remains a challenge.\nGoal Both LuciEntry and DreamCeption explore how interactive systems can be harnessed to facilitate lucid dreaming:\nLuciEntry seeks to simplify and automate the induction of lucid dreams in a lab setting, featuring a modular and autonomous platform that detects REM and delivers multiple cues (visual, auditory, electrical) at the right moment to trigger lucidity. By reducing researchers’ workloads and increasing reliability, LuciEntry aims to make the study of lucid dreaming more systematic and accessible.\nDreamCeption focuses on shaping or “inserting” specific dream themes once a lucid dream is detected, thereby expanding what lucid dreamers can do after attaining lucidity.\nMethod LuciEntry Wake-Back-to-Bed Protocol: Participants sleep 4 hours uninterrupted, then awaken briefly for cognitive training (e.g., MILD). Modular Architecture: A headband with EEG and EOG electrodes connects to a Raspberry Pi server. When sustained REM is detected, the server automatically triggers external cues—LED flashing, binaural beats, and 40 Hz tACS—without researcher intervention. Emergency Button: Users can halt stimulation at any time, ensuring safety and peace of mind. DreamCeption Closed-Loop Detection: Employs brain (EEG) and eye (EOG) sensors to identify when users enter a lucid dream. Targeted Stimuli: Once lucidity is detected (participants move their eyes in a specific pattern, e.g., left-right signals), the system provides stimuli—visual (light), auditory (sound effects), and even haptic or galvanic vestibular stimulation—corresponding to a chosen dream theme (e.g., “scuba diving”). Results LuciEntry In a pilot study with three overnight sessions, two participants reported achieving short lucid dreams after receiving the visual/audio/electrical cues. Demonstrated “dream incorporation,” where external stimuli (flashing lights, sounds) were woven into dream narratives (e.g., seeing brake lights in a racing dream). Identified system hurdles such as sensor calibration, headband comfort, and ensuring fully autonomous operation. DreamCeption Illustrates how well-timed “dream prime” stimuli can lead lucid dreamers to incorporate specific elements (e.g., ocean sounds, bubble haptics) into their dream worlds. Underscores that real-time detection of lucidity is crucial to deliver prompts effectively. Conclusion Taken together, DreamCeption and LuciEntry exemplify how HCI-driven solutions can deepen our engagement with lucid dreaming. DreamCeption offers a vision of content-rich dream design, enabling users to “sculpt” their dream environment. Meanwhile, LuciEntry addresses scalable, automated induction, promising a more robust framework for controlled experiments and eventual personal use. Both open exciting avenues in dream engineering—where carefully timed interventions harness the dreamer’s brain state to either reliably induce or intricately shape dream content.\nThese two prototypes illustrate an emerging intersection of immersive design, biofeedback, and sleep science, pushing beyond conventional VR experiences into the realm of dreams.\nLimitations Signal Quality: EEG and EOG readings can be prone to interference from movement or improper electrode placement, potentially impeding real-time detection. Short Lucid Durations: While users became aware of dreaming, many reported only fleeting moments of lucidity. Lengthening such episodes remains a challenge. Wearability: Discomfort from wearing headsets or electrodes overnight can disrupt sleep and reduce data reliability. Reference The paper: LuciEntry: https://dl.acm.org/doi/10.1145/3613905.3649123 DreamCeption: https://dl.acm.org/doi/10.1145/3613905.3649121 This note was written with the assistance of Generative AI and is based on the content and results presented in the original papers. ","wordCount":"668","inLanguage":"en-us","datePublished":"2024-09-25T20:33:52+08:00","dateModified":"2024-09-25T20:33:52+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://HowardHsuuu.github.io/posts/lr/lucid-interface/"},"publisher":{"@type":"Organization","name":"Notes","logo":{"@type":"ImageObject","url":"https://HowardHsuuu.github.io/images/icon.png"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://HowardHsuuu.github.io/ accesskey=h title="Notes (Alt + H)"><img src=https://HowardHsuuu.github.io/images/icon.png alt aria-label=logo height=35>Notes</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://HowardHsuuu.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://HowardHsuuu.github.io/posts/ title=Topics><span>Topics</span></a></li><li><a href=https://HowardHsuuu.github.io/tags title=Tags><span>Tags</span></a></li><li><a href=https://HowardHsuuu.github.io/aboutme/ title="About Me"><span>About Me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://HowardHsuuu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/>Topics</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/lr/>Literature Review</a></div><h1 class="post-title entry-hint-parent">[LR] Interfacing with Lucid Dreams</h1><div class=post-meta><span title='2024-09-25 20:33:52 +0800 +0800'>September 25, 2024</span>&nbsp;·&nbsp;4 min</div></header><div class=post-content><p>[This review is intended solely for my personal learning]</p><p>Paper Info - LuciEntry</p><blockquote><p>DOI: 10.1145/3613905.3649123<br>Title: LuciEntry: A Modular Lab-based Lucid Dreaming Induction Prototype<br>Authors: Po-Yao (Cosmos) Wang, Nathaniel Lee Yung Xiang, Rohit Rajesh, Antony Smith Loose, Nathan Semertzidis, and Florian ‘Floyd’ Mueller</p></blockquote><p>Paper Info - DreamCeption</p><blockquote><p>DOI: 10.1145/3613905.3649121<br>Title: DreamCeption: Towards Understanding the Design of Targeted Lucid Dream Mediation<br>Authors: Po-Yao (Cosmos) Wang, Rohit Rajesh, Antony Smith Loose, Nathaniel Lee Yung Xiang, Nathalie Overdevest, Nathan Semertzidis, and Florian ‘Floyd’ Mueller</p></blockquote><h2 id=prior-knowledge>Prior Knowledge<a hidden class=anchor aria-hidden=true href=#prior-knowledge>#</a></h2><p>Lucid dreaming is a phenomenon wherein sleepers become aware of dreaming while asleep, often enabling manipulation of dream content and providing potential benefits such as enhanced creativity, nightmare alleviation, and stress relief. Past research has focused on techniques for lucid dream induction (e.g., wake-back-to-bed, mnemonic induction) and explored the use of interactive technologies—such as auditory or visual cues—to influence dream content. However, effectively automating or streamlining this process, as well as helping dreamers shape specific dream topics, remains a challenge.</p><h2 id=goal>Goal<a hidden class=anchor aria-hidden=true href=#goal>#</a></h2><p>Both <strong>LuciEntry</strong> and <strong>DreamCeption</strong> explore how interactive systems can be harnessed to facilitate lucid dreaming:</p><ul><li><p><strong>LuciEntry</strong> seeks to simplify and automate the induction of lucid dreams in a lab setting, featuring a modular and autonomous platform that detects REM and delivers multiple cues (visual, auditory, electrical) at the right moment to trigger lucidity. By reducing researchers’ workloads and increasing reliability, LuciEntry aims to make the study of lucid dreaming more systematic and accessible.</p></li><li><p><strong>DreamCeption</strong> focuses on shaping or “inserting” specific dream themes once a lucid dream is detected, thereby expanding what lucid dreamers can do after attaining lucidity.</p></li></ul><h2 id=method>Method<a hidden class=anchor aria-hidden=true href=#method>#</a></h2><h4 id=lucientry>LuciEntry<a hidden class=anchor aria-hidden=true href=#lucientry>#</a></h4><ol><li><strong>Wake-Back-to-Bed Protocol</strong>: Participants sleep 4 hours uninterrupted, then awaken briefly for cognitive training (e.g., MILD).</li><li><strong>Modular Architecture</strong>: A headband with EEG and EOG electrodes connects to a Raspberry Pi server. When sustained REM is detected, the server automatically triggers external cues—LED flashing, binaural beats, and 40 Hz tACS—without researcher intervention.</li><li><strong>Emergency Button</strong>: Users can halt stimulation at any time, ensuring safety and peace of mind.</li></ol><h4 id=dreamception>DreamCeption<a hidden class=anchor aria-hidden=true href=#dreamception>#</a></h4><ol><li><strong>Closed-Loop Detection</strong>: Employs brain (EEG) and eye (EOG) sensors to identify when users enter a lucid dream.</li><li><strong>Targeted Stimuli</strong>: Once lucidity is detected (participants move their eyes in a specific pattern, e.g., left-right signals), the system provides stimuli—visual (light), auditory (sound effects), and even haptic or galvanic vestibular stimulation—corresponding to a chosen dream theme (e.g., “scuba diving”).</li></ol><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><h4 id=lucientry-1>LuciEntry<a hidden class=anchor aria-hidden=true href=#lucientry-1>#</a></h4><ul><li>In a pilot study with three overnight sessions, two participants reported achieving short lucid dreams after receiving the visual/audio/electrical cues.</li><li>Demonstrated “dream incorporation,” where external stimuli (flashing lights, sounds) were woven into dream narratives (e.g., seeing brake lights in a racing dream).</li><li>Identified system hurdles such as sensor calibration, headband comfort, and ensuring fully autonomous operation.</li></ul><h4 id=dreamception-1>DreamCeption<a hidden class=anchor aria-hidden=true href=#dreamception-1>#</a></h4><ul><li>Illustrates how well-timed “dream prime” stimuli can lead lucid dreamers to incorporate specific elements (e.g., ocean sounds, bubble haptics) into their dream worlds.</li><li>Underscores that real-time detection of lucidity is crucial to deliver prompts effectively.</li></ul><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Taken together, <strong>DreamCeption</strong> and <strong>LuciEntry</strong> exemplify how HCI-driven solutions can deepen our engagement with lucid dreaming. <strong>DreamCeption</strong> offers a vision of <em>content-rich dream design</em>, enabling users to “sculpt” their dream environment. Meanwhile, <strong>LuciEntry</strong> addresses <em>scalable, automated induction</em>, promising a more robust framework for controlled experiments and eventual personal use. Both open exciting avenues in dream engineering—where carefully timed interventions harness the dreamer’s brain state to either reliably induce or intricately shape dream content.</p><p>These two prototypes illustrate an emerging intersection of immersive design, biofeedback, and sleep science, pushing beyond conventional VR experiences into the realm of dreams.</p><h2 id=limitations>Limitations<a hidden class=anchor aria-hidden=true href=#limitations>#</a></h2><ol><li><strong>Signal Quality</strong>: EEG and EOG readings can be prone to interference from movement or improper electrode placement, potentially impeding real-time detection.</li><li><strong>Short Lucid Durations</strong>: While users became aware of dreaming, many reported only fleeting moments of lucidity. Lengthening such episodes remains a challenge.</li><li><strong>Wearability</strong>: Discomfort from wearing headsets or electrodes overnight can disrupt sleep and reduce data reliability.</li></ol><hr><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><ul><li>The paper:<ul><li>LuciEntry: <a href=https://dl.acm.org/doi/10.1145/3613905.3649123>https://dl.acm.org/doi/10.1145/3613905.3649123</a></li><li>DreamCeption: <a href=https://dl.acm.org/doi/10.1145/3613905.3649121>https://dl.acm.org/doi/10.1145/3613905.3649121</a></li></ul></li><li>This note was written with the assistance of Generative AI and is based on the content and results presented in the original papers.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://HowardHsuuu.github.io/tags/human-computer-interaction/>Human-Computer Interaction</a></li></ul><nav class=paginav><a class=prev href=https://HowardHsuuu.github.io/posts/lr/quixer/><span class=title>«</span><br><span>[LR] Quixer: A Quantum Transformer Model</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://HowardHsuuu.github.io/>Notes</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script type=text/javascript src=/js/canvas-nest.js count=80 color=102,255,178 opacity=1></script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>