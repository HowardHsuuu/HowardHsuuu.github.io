<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[LR] Predicting Whole-Brain Neural Dynamics from Prefrontal Cortex fNIRS Signal | Notes</title>
<meta name=keywords content="fNIRS,fMRI,Neuroscience"><meta name=description content="[This review is intended solely for my personal learning]
Paper Info

DOI: 10.1101/2024.11.17.623979
Title: Predicting whole-brain neural dynamics from prefrontal cortex fNIRS signal during movie-watching
Authors: Shan Gao, Ryleigh Nash, Shannon Burns, Yuan Chang Leong
Prior Knowledge
Functional near-infrared spectroscopy (fNIRS) offers a more accessible alternative to functional magnetic resonance imaging (fMRI) but is limited by shallow cortical penetration. Prior research has demonstrated potential in predicting deep-brain fMRI signals from fNIRS data through linear predictive models trained on simultaneous fMRI and fNIRS measurements."><meta name=author content><link rel=canonical href=https://HowardHsuuu.github.io/posts/lr/fnirs2fmri/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=icon type=image/png sizes=16x16 href=https://HowardHsuuu.github.io/images/icon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://HowardHsuuu.github.io/images/icon-32x32.png><link rel=apple-touch-icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=mask-icon href=https://HowardHsuuu.github.io/images/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://HowardHsuuu.github.io/posts/lr/fnirs2fmri/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-...some_hash... crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="[LR] Predicting Whole-Brain Neural Dynamics from Prefrontal Cortex fNIRS Signal"><meta property="og:description" content="[This review is intended solely for my personal learning]
Paper Info

DOI: 10.1101/2024.11.17.623979
Title: Predicting whole-brain neural dynamics from prefrontal cortex fNIRS signal during movie-watching
Authors: Shan Gao, Ryleigh Nash, Shannon Burns, Yuan Chang Leong
Prior Knowledge
Functional near-infrared spectroscopy (fNIRS) offers a more accessible alternative to functional magnetic resonance imaging (fMRI) but is limited by shallow cortical penetration. Prior research has demonstrated potential in predicting deep-brain fMRI signals from fNIRS data through linear predictive models trained on simultaneous fMRI and fNIRS measurements."><meta property="og:type" content="article"><meta property="og:url" content="https://HowardHsuuu.github.io/posts/lr/fnirs2fmri/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-17T15:32:01+08:00"><meta property="article:modified_time" content="2025-03-17T15:32:01+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[LR] Predicting Whole-Brain Neural Dynamics from Prefrontal Cortex fNIRS Signal"><meta name=twitter:description content="[This review is intended solely for my personal learning]
Paper Info

DOI: 10.1101/2024.11.17.623979
Title: Predicting whole-brain neural dynamics from prefrontal cortex fNIRS signal during movie-watching
Authors: Shan Gao, Ryleigh Nash, Shannon Burns, Yuan Chang Leong
Prior Knowledge
Functional near-infrared spectroscopy (fNIRS) offers a more accessible alternative to functional magnetic resonance imaging (fMRI) but is limited by shallow cortical penetration. Prior research has demonstrated potential in predicting deep-brain fMRI signals from fNIRS data through linear predictive models trained on simultaneous fMRI and fNIRS measurements."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Topics","item":"https://HowardHsuuu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Literature Review","item":"https://HowardHsuuu.github.io/posts/lr/"},{"@type":"ListItem","position":3,"name":"[LR] Predicting Whole-Brain Neural Dynamics from Prefrontal Cortex fNIRS Signal","item":"https://HowardHsuuu.github.io/posts/lr/fnirs2fmri/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[LR] Predicting Whole-Brain Neural Dynamics from Prefrontal Cortex fNIRS Signal","name":"[LR] Predicting Whole-Brain Neural Dynamics from Prefrontal Cortex fNIRS Signal","description":"[This review is intended solely for my personal learning]\nPaper Info\nDOI: 10.1101/2024.11.17.623979\nTitle: Predicting whole-brain neural dynamics from prefrontal cortex fNIRS signal during movie-watching\nAuthors: Shan Gao, Ryleigh Nash, Shannon Burns, Yuan Chang Leong\nPrior Knowledge Functional near-infrared spectroscopy (fNIRS) offers a more accessible alternative to functional magnetic resonance imaging (fMRI) but is limited by shallow cortical penetration. Prior research has demonstrated potential in predicting deep-brain fMRI signals from fNIRS data through linear predictive models trained on simultaneous fMRI and fNIRS measurements.\n","keywords":["fNIRS","fMRI","Neuroscience"],"articleBody":"[This review is intended solely for my personal learning]\nPaper Info\nDOI: 10.1101/2024.11.17.623979\nTitle: Predicting whole-brain neural dynamics from prefrontal cortex fNIRS signal during movie-watching\nAuthors: Shan Gao, Ryleigh Nash, Shannon Burns, Yuan Chang Leong\nPrior Knowledge Functional near-infrared spectroscopy (fNIRS) offers a more accessible alternative to functional magnetic resonance imaging (fMRI) but is limited by shallow cortical penetration. Prior research has demonstrated potential in predicting deep-brain fMRI signals from fNIRS data through linear predictive models trained on simultaneous fMRI and fNIRS measurements.\nGoal The primary goal of this study was to develop and validate a predictive model capable of mapping localized fNIRS signals from the prefrontal cortex (PFC) to whole-brain neural dynamics measured by fMRI during naturalistic tasks, specifically movie-watching. This approach aims to overcome the spatial limitations of fNIRS by inferring neural activity in deeper and distant brain regions from accessible cortical signals.\nMethod The study employed fNIRS data collected from 29 participants as they watched a 48-minute episode from a television series, paired with publicly available fMRI data from participants watching the same content. The analysis involved:\nPrincipal Component Regression (PCR) modeling to map prefrontal fNIRS signals onto whole-brain fMRI signals. Model training using the first half of the episode and testing on a separate held-out participant watching the second half, evaluating cross-individual and cross-stimulus generalization. Semantic analysis by encoding narrative content into vector embeddings, testing if the predicted fMRI time courses retained semantic information. Assessments of model predictions through correlations between observed and predicted fMRI activity and inter-subject functional connectivity (ISFC). Results The predictive model successfully inferred fMRI activity significantly above chance in 66 out of 122 brain regions, including areas inaccessible to fNIRS, such as the temporal poles, precuneus, posterior cingulate cortex, and basal ganglia. The model achieved the highest accuracy in the default mode and control networks, consistent with their roles in higher-order cognition and narrative processing.\nThe predicted fMRI data replicated inter-subject functional connectivity patterns observed in the actual fMRI data (ISFC correlation: r = 0.42, p \u003c .001). Semantic encoding analyses demonstrated that predicted fMRI signals retained meaningful semantic information, especially in language processing regions and the dorsomedial prefrontal cortex.\nLimitations The model’s reliance on naturalistic stimuli may limit generalizability to different contexts or cognitive tasks, particularly those engaging regions underrepresented in the current stimuli, such as somatomotor areas. Idiosyncratic neural responses, notably in regions like the ventromedial prefrontal cortex, were less effectively predicted due to inherent variability between individuals. Predictive accuracy might benefit from the use of individual-specific modeling approaches, possibly requiring simultaneous fNIRS and fMRI recordings for optimization. Reference The paper: https://doi.org/10.1101/2024.11.17.623979 This note was written with the assistance of Generative AI and is based on the content and results presented in the original paper. ","wordCount":"455","inLanguage":"en-us","datePublished":"2025-03-17T15:32:01+08:00","dateModified":"2025-03-17T15:32:01+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://HowardHsuuu.github.io/posts/lr/fnirs2fmri/"},"publisher":{"@type":"Organization","name":"Notes","logo":{"@type":"ImageObject","url":"https://HowardHsuuu.github.io/images/icon.png"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://HowardHsuuu.github.io/ accesskey=h title="Notes (Alt + H)"><img src=https://HowardHsuuu.github.io/images/icon.png alt aria-label=logo height=35>Notes</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://HowardHsuuu.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://HowardHsuuu.github.io/posts/ title=Topics><span>Topics</span></a></li><li><a href=https://HowardHsuuu.github.io/tags title=Tags><span>Tags</span></a></li><li><a href=https://HowardHsuuu.github.io/aboutme/ title="About Me"><span>About Me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://HowardHsuuu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/>Topics</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/lr/>Literature Review</a></div><h1 class="post-title entry-hint-parent">[LR] Predicting Whole-Brain Neural Dynamics from Prefrontal Cortex fNIRS Signal</h1><div class=post-meta><span title='2025-03-17 15:32:01 +0800 +0800'>March 17, 2025</span>&nbsp;·&nbsp;3 min</div></header><div class=post-content><p>[This review is intended solely for my personal learning]</p><p>Paper Info</p><blockquote><p>DOI: <a href=https://doi.org/10.1101/2024.11.17.623979>10.1101/2024.11.17.623979</a><br>Title: Predicting whole-brain neural dynamics from prefrontal cortex fNIRS signal during movie-watching<br>Authors: Shan Gao, Ryleigh Nash, Shannon Burns, Yuan Chang Leong</p></blockquote><h2 id=prior-knowledge>Prior Knowledge<a hidden class=anchor aria-hidden=true href=#prior-knowledge>#</a></h2><p>Functional near-infrared spectroscopy (fNIRS) offers a more accessible alternative to functional magnetic resonance imaging (fMRI) but is limited by shallow cortical penetration. Prior research has demonstrated potential in predicting deep-brain fMRI signals from fNIRS data through linear predictive models trained on simultaneous fMRI and fNIRS measurements.</p><h2 id=goal>Goal<a hidden class=anchor aria-hidden=true href=#goal>#</a></h2><p>The primary goal of this study was to develop and validate a predictive model capable of mapping localized fNIRS signals from the prefrontal cortex (PFC) to whole-brain neural dynamics measured by fMRI during naturalistic tasks, specifically movie-watching. This approach aims to overcome the spatial limitations of fNIRS by inferring neural activity in deeper and distant brain regions from accessible cortical signals.</p><h2 id=method>Method<a hidden class=anchor aria-hidden=true href=#method>#</a></h2><p>The study employed fNIRS data collected from 29 participants as they watched a 48-minute episode from a television series, paired with publicly available fMRI data from participants watching the same content. The analysis involved:</p><ul><li>Principal Component Regression (PCR) modeling to map prefrontal fNIRS signals onto whole-brain fMRI signals.</li><li>Model training using the first half of the episode and testing on a separate held-out participant watching the second half, evaluating cross-individual and cross-stimulus generalization.</li><li>Semantic analysis by encoding narrative content into vector embeddings, testing if the predicted fMRI time courses retained semantic information.</li><li>Assessments of model predictions through correlations between observed and predicted fMRI activity and inter-subject functional connectivity (ISFC).</li></ul><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><p>The predictive model successfully inferred fMRI activity significantly above chance in 66 out of 122 brain regions, including areas inaccessible to fNIRS, such as the temporal poles, precuneus, posterior cingulate cortex, and basal ganglia. The model achieved the highest accuracy in the default mode and control networks, consistent with their roles in higher-order cognition and narrative processing.</p><p>The predicted fMRI data replicated inter-subject functional connectivity patterns observed in the actual fMRI data (ISFC correlation: r = 0.42, p &lt; .001). Semantic encoding analyses demonstrated that predicted fMRI signals retained meaningful semantic information, especially in language processing regions and the dorsomedial prefrontal cortex.</p><h2 id=limitations>Limitations<a hidden class=anchor aria-hidden=true href=#limitations>#</a></h2><ul><li>The model&rsquo;s reliance on naturalistic stimuli may limit generalizability to different contexts or cognitive tasks, particularly those engaging regions underrepresented in the current stimuli, such as somatomotor areas.</li><li>Idiosyncratic neural responses, notably in regions like the ventromedial prefrontal cortex, were less effectively predicted due to inherent variability between individuals.</li><li>Predictive accuracy might benefit from the use of individual-specific modeling approaches, possibly requiring simultaneous fNIRS and fMRI recordings for optimization.</li></ul><hr><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><ul><li>The paper: <a href=https://doi.org/10.1101/2024.11.17.623979>https://doi.org/10.1101/2024.11.17.623979</a></li><li>This note was written with the assistance of Generative AI and is based on the content and results presented in the original paper.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://HowardHsuuu.github.io/tags/fnirs/>FNIRS</a></li><li><a href=https://HowardHsuuu.github.io/tags/fmri/>FMRI</a></li><li><a href=https://HowardHsuuu.github.io/tags/neuroscience/>Neuroscience</a></li></ul><nav class=paginav><a class=prev href=https://HowardHsuuu.github.io/posts/lr/eeg-emotion-recognition/><span class=title>«</span><br><span>[LR] Swarm Intelligence for EEG Channel Selection in Emotion Recognition</span>
</a><a class=next href=https://HowardHsuuu.github.io/posts/lr/queegnet/><span class=title>»</span><br><span>[LR] quEEGNet: QAI for Biosignal Processing</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://HowardHsuuu.github.io/>Notes</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script type=text/javascript src=/js/canvas-nest.js count=80 color=102,255,178 opacity=1></script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>