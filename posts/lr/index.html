<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Literature Review | Notes</title>
<meta name=keywords content><meta name=description content="Literature Review - Notes"><meta name=author content><link rel=canonical href=https://HowardHsuuu.github.io/posts/lr/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=icon type=image/png sizes=16x16 href=https://HowardHsuuu.github.io/images/icon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://HowardHsuuu.github.io/images/icon-32x32.png><link rel=apple-touch-icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=mask-icon href=https://HowardHsuuu.github.io/images/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://HowardHsuuu.github.io/posts/lr/index.xml><link rel=alternate hreflang=en-us href=https://HowardHsuuu.github.io/posts/lr/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-...some_hash... crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="Literature Review"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://HowardHsuuu.github.io/posts/lr/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Literature Review"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Topics","item":"https://HowardHsuuu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Literature Review","item":"https://HowardHsuuu.github.io/posts/lr/"}]}</script></head><body class="list dark" id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://HowardHsuuu.github.io/ accesskey=h title="Notes (Alt + H)"><img src=https://HowardHsuuu.github.io/images/icon.png alt aria-label=logo height=35>Notes</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://HowardHsuuu.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://HowardHsuuu.github.io/posts/ title=Topics><span>Topics</span></a></li><li><a href=https://HowardHsuuu.github.io/tags title=Tags><span>Tags</span></a></li><li><a href=https://HowardHsuuu.github.io/aboutme/ title="About Me"><span>About Me</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://HowardHsuuu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/>Topics</a></div><h1>Literature Review</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] Steering Language Models With Activation Engineering</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
Paper Info arXiv: 2308.10248
Title: Steering Language Models With Activation Engineering
Authors: Alexander Matt Turner, David Udell, Nantas Nardelli, Sam Ringer, Tom McGrath, Eric Michaud, Mantas Mazeika
Prior Knowledge Steering Language Models: Traditionally achieved through techniques such as prompt engineering, fine-tuning, and reinforcement learning from human feedback (RLHF), which often require substantial computational resources and specialized datasets. Internal Activation Manipulation: Exploring internal activations of neural networks can offer fine-grained control over their outputs without the cost associated with retraining or extensive model tuning. Goal The paper aims to introduce and validate a lightweight inference-time technique, termed Activation Addition (ActAdd), for steering the output of large language models (LLMs). This method targets latent capabilities of LLMs, such as controlled sentiment expression or reduced output toxicity, without the need for additional training.
...</p></div><footer class=entry-footer><span title='2025-03-26 20:12:03 +0800 +0800'>March 26, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [LR] Steering Language Models With Activation Engineering" href=https://HowardHsuuu.github.io/posts/lr/actadd/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] Representation Engineering: Top-Down AI Transparency</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
Paper Info
arXiv: 2310.01405v4
Title: Representation Engineering: A Top-Down Approach to AI Transparency
Authors: Evan Hubinger, Ajeya Cotra, Buck Shlegeris, Tom Lieberum, Nicholas Joseph, Owain Evans, Nicholas Schiefer, Oliver Zhang, Jan Brauner, Collin Burns, Leo Gao, Ryan Greenblatt
Prior Knowledge Interpretability in AI: Traditional approaches often focus on low-level features such as neurons or circuits. However, such bottom-up analysis struggles with high-level abstractions like honesty or power-seeking. Representation Learning: Neural networks form internal embeddings of concepts during training, enabling powerful generalization and emergent behavior. Mechanistic Interpretability: Aims to reverse-engineer model internals to understand reasoning processes, but often lacks tools for directly modifying internal representations to improve safety. Transparency and Alignment: Transparency is critical for ensuring model behavior is aligned with human intentions and values, particularly to avoid deceptive alignment and inner misalignment. Goal The paper proposes and develops Representation Engineering (RepE), a new top-down framework for interpretability and model control. Rather than focusing on neurons or circuits, RepE centers on representations of high-level cognitive concepts and aims to understand, detect, and manipulate them. The core goal is to advance transparency methods that are directly useful for improving AI safety, including controlling undesirable behaviors like deception or power-seeking.
...</p></div><footer class=entry-footer><span title='2025-03-25 20:12:03 +0800 +0800'>March 25, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [LR] Representation Engineering: Top-Down AI Transparency" href=https://HowardHsuuu.github.io/posts/lr/repe/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] Swarm Intelligence for EEG Channel Selection in Emotion Recognition</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
Paper Info
DOI: 10.1007/978-3-031-05409-9_23
Title: A Swarm Intelligence Approach: Combination of Different EEG-Channel Optimization Techniques to Enhance Emotion Recognition
Authors: Sabahudin Balic, Lukas Kleybolte, and Christian Märtin
Prior Knowledge EEG-based Emotion Recognition: EEG captures electrical brain activity via multiple electrodes. Its high temporal resolution makes it suitable for decoding emotional states in real-time. However, the full 32-channel setup is often computationally expensive and redundant. Swarm Intelligence: Algorithms like Particle Swarm Optimization (PSO), Cuckoo Search (CS), and Grey Wolf Optimizer (GWO) mimic social behavior of animals to solve optimization problems. Feature vs. Channel Selection: Traditional feature selection targets discriminative features across frequency bands, while channel selection focuses on spatially optimizing electrode positions. Goal To evaluate and compare different EEG channel selection techniques—both classical and swarm intelligence-based—to optimize emotion classification performance while significantly reducing computation time.
...</p></div><footer class=entry-footer><span title='2025-03-22 19:21:17 +0800 +0800'>March 22, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [LR] Swarm Intelligence for EEG Channel Selection in Emotion Recognition" href=https://HowardHsuuu.github.io/posts/lr/eeg-emotion-recognition/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] quEEGNet: QAI for Biosignal Processing</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
Paper Info
arXiv: 2210.00864v1
Title: quEEGNet: Quantum AI for Biosignal Processing
Authors: Toshiaki Koike-Akino, Ye Wang
Prior Knowledge Biosignal Processing in Human-Machine Interfaces (HMI) Biosignals such as EEG (electroencephalogram), EMG (electromyogram), and ECoG (electrocorticogram) are fundamental to developing brain-computer interfaces (BCI) and HMIs. However, biosignals are subject to high variability and noise, requiring robust machine-learning models for feature extraction and classification.
...</p></div><footer class=entry-footer><span title='2025-02-11 19:51:02 +0800 +0800'>February 11, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [LR] quEEGNet: QAI for Biosignal Processing" href=https://HowardHsuuu.github.io/posts/lr/queegnet/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[LR] The Flatland Fallacy</h2></header><div class=entry-content><p>[This review is intended solely for my personal learning]
Paper Info DOI: 10.1111/tops.12404
Title: The Flatland Fallacy: Moving Beyond Low–Dimensional Thinking
Authors: Eshin Jolly, Luke J. Chang
Prior Knowledge Psychological and cognitive sciences have long relied on simplified, low-dimensional models to explain complex human behavior. While these models provide theoretical clarity and empirical tractability, they often fail to capture the full intricacy of psychological phenomena. The reliance on two-factor or low-dimensional frameworks—such as dual-process theories of cognition—raises concerns about scientific oversimplification.
...</p></div><footer class=entry-footer><span title='2025-02-09 20:01:09 +0800 +0800'>February 9, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [LR] The Flatland Fallacy" href=https://HowardHsuuu.github.io/posts/lr/flatland-fallacy/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://HowardHsuuu.github.io/posts/lr/page/2/>&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://HowardHsuuu.github.io/>Notes</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script type=text/javascript src=/js/canvas-nest.js count=80 color=102,255,178 opacity=1></script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>