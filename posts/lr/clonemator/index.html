<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[LR] Clonemator: Spatiotemporal Clones in VR | Notes</title>
<meta name=keywords content="Human-Computer Interaction,Virtual Reality"><meta name=description content="[This review is intended solely for my personal learning]
[The VR project, ChronoClones, in OpenHCI 2024 was based on this paper]
Paper Info

arXiv: 2311.04427
Title: Clonemator: Composing Spatiotemporal Clones to Create Interactive Automators in Virtual Reality
Authors: Yi-Shuo Lin, Ching-Yi Tsai, Lung-Pan Cheng
Prior Knowledge

Interaction Techniques in VR: Traditional approaches (e.g., Go-Go, portals) focus on specific tasks or single-avatar enhancements. While helpful, these designs rarely offer a broad, integrative way to handle diverse, complex interactions without pre-coded solutions.
Programming by Demonstration (PbD): Non-VR automation tools like Sikuli or Ringer let users capture and replay interactions to automate tasks. However, applying PbD to immersive VR—where physical presence, body movement, and 3D spatial context matter—is underexplored.

Goal
Clonemator aims to let users create and collaborate with virtual “clones” of themselves to accomplish complex or repetitive tasks, all without manual scripting. By allowing clones to be configured across space (e.g., different locations, scales) and time (e.g., static pose, synchronous motion, or replayed actions), the system seeks to empower users to construct flexible, intuitive “automators” for tasks ranging from object manipulation to cooperative assemblies."><meta name=author content><link rel=canonical href=https://HowardHsuuu.github.io/posts/lr/clonemator/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=icon type=image/png sizes=16x16 href=https://HowardHsuuu.github.io/images/icon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://HowardHsuuu.github.io/images/icon-32x32.png><link rel=apple-touch-icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=mask-icon href=https://HowardHsuuu.github.io/images/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://HowardHsuuu.github.io/posts/lr/clonemator/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-...some_hash... crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="[LR] Clonemator: Spatiotemporal Clones in VR"><meta property="og:description" content="[This review is intended solely for my personal learning]
[The VR project, ChronoClones, in OpenHCI 2024 was based on this paper]
Paper Info

arXiv: 2311.04427
Title: Clonemator: Composing Spatiotemporal Clones to Create Interactive Automators in Virtual Reality
Authors: Yi-Shuo Lin, Ching-Yi Tsai, Lung-Pan Cheng
Prior Knowledge

Interaction Techniques in VR: Traditional approaches (e.g., Go-Go, portals) focus on specific tasks or single-avatar enhancements. While helpful, these designs rarely offer a broad, integrative way to handle diverse, complex interactions without pre-coded solutions.
Programming by Demonstration (PbD): Non-VR automation tools like Sikuli or Ringer let users capture and replay interactions to automate tasks. However, applying PbD to immersive VR—where physical presence, body movement, and 3D spatial context matter—is underexplored.

Goal
Clonemator aims to let users create and collaborate with virtual “clones” of themselves to accomplish complex or repetitive tasks, all without manual scripting. By allowing clones to be configured across space (e.g., different locations, scales) and time (e.g., static pose, synchronous motion, or replayed actions), the system seeks to empower users to construct flexible, intuitive “automators” for tasks ranging from object manipulation to cooperative assemblies."><meta property="og:type" content="article"><meta property="og:url" content="https://HowardHsuuu.github.io/posts/lr/clonemator/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-27T19:56:26+08:00"><meta property="article:modified_time" content="2024-09-27T19:56:26+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[LR] Clonemator: Spatiotemporal Clones in VR"><meta name=twitter:description content="[This review is intended solely for my personal learning]
[The VR project, ChronoClones, in OpenHCI 2024 was based on this paper]
Paper Info

arXiv: 2311.04427
Title: Clonemator: Composing Spatiotemporal Clones to Create Interactive Automators in Virtual Reality
Authors: Yi-Shuo Lin, Ching-Yi Tsai, Lung-Pan Cheng
Prior Knowledge

Interaction Techniques in VR: Traditional approaches (e.g., Go-Go, portals) focus on specific tasks or single-avatar enhancements. While helpful, these designs rarely offer a broad, integrative way to handle diverse, complex interactions without pre-coded solutions.
Programming by Demonstration (PbD): Non-VR automation tools like Sikuli or Ringer let users capture and replay interactions to automate tasks. However, applying PbD to immersive VR—where physical presence, body movement, and 3D spatial context matter—is underexplored.

Goal
Clonemator aims to let users create and collaborate with virtual “clones” of themselves to accomplish complex or repetitive tasks, all without manual scripting. By allowing clones to be configured across space (e.g., different locations, scales) and time (e.g., static pose, synchronous motion, or replayed actions), the system seeks to empower users to construct flexible, intuitive “automators” for tasks ranging from object manipulation to cooperative assemblies."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Topics","item":"https://HowardHsuuu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Literature Review","item":"https://HowardHsuuu.github.io/posts/lr/"},{"@type":"ListItem","position":3,"name":"[LR] Clonemator: Spatiotemporal Clones in VR","item":"https://HowardHsuuu.github.io/posts/lr/clonemator/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[LR] Clonemator: Spatiotemporal Clones in VR","name":"[LR] Clonemator: Spatiotemporal Clones in VR","description":"[This review is intended solely for my personal learning]\n[The VR project, ChronoClones, in OpenHCI 2024 was based on this paper]\nPaper Info\narXiv: 2311.04427\nTitle: Clonemator: Composing Spatiotemporal Clones to Create Interactive Automators in Virtual Reality\nAuthors: Yi-Shuo Lin, Ching-Yi Tsai, Lung-Pan Cheng\nPrior Knowledge Interaction Techniques in VR: Traditional approaches (e.g., Go-Go, portals) focus on specific tasks or single-avatar enhancements. While helpful, these designs rarely offer a broad, integrative way to handle diverse, complex interactions without pre-coded solutions. Programming by Demonstration (PbD): Non-VR automation tools like Sikuli or Ringer let users capture and replay interactions to automate tasks. However, applying PbD to immersive VR—where physical presence, body movement, and 3D spatial context matter—is underexplored. Goal Clonemator aims to let users create and collaborate with virtual “clones” of themselves to accomplish complex or repetitive tasks, all without manual scripting. By allowing clones to be configured across space (e.g., different locations, scales) and time (e.g., static pose, synchronous motion, or replayed actions), the system seeks to empower users to construct flexible, intuitive “automators” for tasks ranging from object manipulation to cooperative assemblies.\n","keywords":["Human-Computer Interaction","Virtual Reality"],"articleBody":"[This review is intended solely for my personal learning]\n[The VR project, ChronoClones, in OpenHCI 2024 was based on this paper]\nPaper Info\narXiv: 2311.04427\nTitle: Clonemator: Composing Spatiotemporal Clones to Create Interactive Automators in Virtual Reality\nAuthors: Yi-Shuo Lin, Ching-Yi Tsai, Lung-Pan Cheng\nPrior Knowledge Interaction Techniques in VR: Traditional approaches (e.g., Go-Go, portals) focus on specific tasks or single-avatar enhancements. While helpful, these designs rarely offer a broad, integrative way to handle diverse, complex interactions without pre-coded solutions. Programming by Demonstration (PbD): Non-VR automation tools like Sikuli or Ringer let users capture and replay interactions to automate tasks. However, applying PbD to immersive VR—where physical presence, body movement, and 3D spatial context matter—is underexplored. Goal Clonemator aims to let users create and collaborate with virtual “clones” of themselves to accomplish complex or repetitive tasks, all without manual scripting. By allowing clones to be configured across space (e.g., different locations, scales) and time (e.g., static pose, synchronous motion, or replayed actions), the system seeks to empower users to construct flexible, intuitive “automators” for tasks ranging from object manipulation to cooperative assemblies.\nMethod System Components\nSpatial Manipulations: Spawn Methods: Direct, Indirect, Auto, and Relative allow users to generate clones at specific positions or in bulk. Movement \u0026 Control: Users can switch first-person perspective to any clone, group them to lock relative positioning, mirror or scale them, etc. Temporal Modes: Static: The clone remains “frozen” in the spawned pose. Synchronous: The clone mimics the user’s real-time movements. Replay: The clone executes recorded actions (including object interactions) on a loop. Implementation\nBuilt in Unity for a Meta Quest 2 setup. Avatars animate via inverse kinematics from headset/controller input. A wrist-mounted menu and voice commands handle cloning and mode changes. Preliminary User Study\nParticipants: 12 volunteers, mostly with little VR experience. Procedure: Two parts: (a) a tutorial with guided tasks—hammering pegs, catching fish, fanning flames while cooking; (b) independent tasks where participants devised strategies for challenges like moving heavy objects or retrieving items from high shelves. Observations: Noted solution diversity, user feedback on intuitiveness, any difficulties encountered. Results Creative Compositions: Participants tackled the same tasks with varied strategies. For instance, one formed a “bucket brigade” of clones passing objects synchronously; another stacked static clones as a step stool to reach elevated items. Ease of Use: Many found direct spawning and synchronous control “very natural,” particularly once they realized clones could hold objects, mirror movements, and be grouped or duplicated. Conclusion Clonemator expands VR interaction beyond one-body, one-task paradigms. By combining key PbD principles—recording user actions—and flexible re-spawning of those actions in clone form, it enables a user-friendly path to on-the-fly automation. Early evidence suggests that novices rapidly adopt these spatiotemporal cloning techniques to build surprisingly complex solutions in VR without explicit programming.\nLimitations Limited Body Tracking: Only headset and controllers drive the full-body avatar, restricting lower-body fidelity. Precise Alignment Needs: Complex tasks sometimes require further “snapping” or advanced positioning aids to ensure clones align exactly with small targets. Cognitive Load: Managing many clones with different timings can overwhelm users in intricate scenarios. Replay Editing: Replaying continuous user actions is powerful, but advanced editing or partial replays could further expand utility. Reference The paper: https://arxiv.org/abs/2311.04427 This note was written with the assistance of Generative AI and is based on the content and results presented in the original paper. ","wordCount":"554","inLanguage":"en-us","datePublished":"2024-09-27T19:56:26+08:00","dateModified":"2024-09-27T19:56:26+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://HowardHsuuu.github.io/posts/lr/clonemator/"},"publisher":{"@type":"Organization","name":"Notes","logo":{"@type":"ImageObject","url":"https://HowardHsuuu.github.io/images/icon.png"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://HowardHsuuu.github.io/ accesskey=h title="Notes (Alt + H)"><img src=https://HowardHsuuu.github.io/images/icon.png alt aria-label=logo height=35>Notes</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://HowardHsuuu.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://HowardHsuuu.github.io/posts/ title=Topics><span>Topics</span></a></li><li><a href=https://HowardHsuuu.github.io/tags title=Tags><span>Tags</span></a></li><li><a href=https://HowardHsuuu.github.io/aboutme/ title="About Me"><span>About Me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://HowardHsuuu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/>Topics</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/lr/>Literature Review</a></div><h1 class="post-title entry-hint-parent">[LR] Clonemator: Spatiotemporal Clones in VR</h1><div class=post-meta><span title='2024-09-27 19:56:26 +0800 +0800'>September 27, 2024</span>&nbsp;·&nbsp;3 min</div></header><div class=post-content><p>[This review is intended solely for my personal learning]</p><p>[The VR project, <strong>ChronoClones</strong>, in OpenHCI 2024 was based on this paper]</p><p>Paper Info</p><blockquote><p>arXiv: 2311.04427<br>Title: Clonemator: Composing Spatiotemporal Clones to Create Interactive Automators in Virtual Reality<br>Authors: Yi-Shuo Lin, Ching-Yi Tsai, Lung-Pan Cheng</p></blockquote><h2 id=prior-knowledge>Prior Knowledge<a hidden class=anchor aria-hidden=true href=#prior-knowledge>#</a></h2><ul><li><strong>Interaction Techniques in VR</strong>: Traditional approaches (e.g., Go-Go, portals) focus on specific tasks or single-avatar enhancements. While helpful, these designs rarely offer a broad, integrative way to handle diverse, complex interactions without pre-coded solutions.</li><li><strong>Programming by Demonstration (PbD)</strong>: Non-VR automation tools like Sikuli or Ringer let users capture and replay interactions to automate tasks. However, applying PbD to immersive VR—where physical presence, body movement, and 3D spatial context matter—is underexplored.</li></ul><h2 id=goal>Goal<a hidden class=anchor aria-hidden=true href=#goal>#</a></h2><p>Clonemator aims to let users create and collaborate with virtual “clones” of themselves to accomplish complex or repetitive tasks, all without manual scripting. By allowing clones to be configured across space (e.g., different locations, scales) and time (e.g., static pose, synchronous motion, or replayed actions), the system seeks to empower users to construct flexible, intuitive “automators” for tasks ranging from object manipulation to cooperative assemblies.</p><h2 id=method>Method<a hidden class=anchor aria-hidden=true href=#method>#</a></h2><ol><li><p><strong>System Components</strong></p><ul><li><strong>Spatial Manipulations</strong>:<ul><li><em>Spawn Methods</em>: Direct, Indirect, Auto, and Relative allow users to generate clones at specific positions or in bulk.</li><li><em>Movement & Control</em>: Users can switch first-person perspective to any clone, group them to lock relative positioning, mirror or scale them, etc.</li></ul></li><li><strong>Temporal Modes</strong>:<ol><li><em>Static</em>: The clone remains “frozen” in the spawned pose.</li><li><em>Synchronous</em>: The clone mimics the user’s real-time movements.</li><li><em>Replay</em>: The clone executes recorded actions (including object interactions) on a loop.</li></ol></li></ul></li><li><p><strong>Implementation</strong></p><ul><li>Built in Unity for a Meta Quest 2 setup. Avatars animate via inverse kinematics from headset/controller input. A wrist-mounted menu and voice commands handle cloning and mode changes.</li></ul></li><li><p><strong>Preliminary User Study</strong></p><ul><li><strong>Participants</strong>: 12 volunteers, mostly with little VR experience.</li><li><strong>Procedure</strong>: Two parts: (a) a tutorial with guided tasks—hammering pegs, catching fish, fanning flames while cooking; (b) independent tasks where participants devised strategies for challenges like moving heavy objects or retrieving items from high shelves.</li><li><strong>Observations</strong>: Noted solution diversity, user feedback on intuitiveness, any difficulties encountered.</li></ul></li></ol><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><ul><li><strong>Creative Compositions</strong>: Participants tackled the same tasks with varied strategies. For instance, one formed a “bucket brigade” of clones passing objects synchronously; another stacked static clones as a step stool to reach elevated items.</li><li><strong>Ease of Use</strong>: Many found direct spawning and synchronous control “very natural,” particularly once they realized clones could hold objects, mirror movements, and be grouped or duplicated.</li></ul><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Clonemator expands VR interaction beyond one-body, one-task paradigms. By combining key PbD principles—recording user actions—and flexible re-spawning of those actions in clone form, it enables a user-friendly path to on-the-fly automation. Early evidence suggests that novices rapidly adopt these spatiotemporal cloning techniques to build surprisingly complex solutions in VR without explicit programming.</p><h2 id=limitations>Limitations<a hidden class=anchor aria-hidden=true href=#limitations>#</a></h2><ol><li><strong>Limited Body Tracking</strong>: Only headset and controllers drive the full-body avatar, restricting lower-body fidelity.</li><li><strong>Precise Alignment Needs</strong>: Complex tasks sometimes require further “snapping” or advanced positioning aids to ensure clones align exactly with small targets.</li><li><strong>Cognitive Load</strong>: Managing many clones with different timings can overwhelm users in intricate scenarios.</li><li><strong>Replay Editing</strong>: Replaying continuous user actions is powerful, but advanced editing or partial replays could further expand utility.</li></ol><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><ul><li>The paper: <a href=https://arxiv.org/abs/2311.04427>https://arxiv.org/abs/2311.04427</a></li><li>This note was written with the assistance of Generative AI and is based on the content and results presented in the original paper.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://HowardHsuuu.github.io/tags/human-computer-interaction/>Human-Computer Interaction</a></li><li><a href=https://HowardHsuuu.github.io/tags/virtual-reality/>Virtual Reality</a></li></ul><nav class=paginav><a class=prev href=https://HowardHsuuu.github.io/posts/lr/ssvep-bci/><span class=title>«</span><br><span>[LR] Binocular Vision SSVEP BCI for Dual-Frequency Modulation</span>
</a><a class=next href=https://HowardHsuuu.github.io/posts/lr/quixer/><span class=title>»</span><br><span>[LR] Quixer: A Quantum Transformer Model</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://HowardHsuuu.github.io/>Notes</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script type=text/javascript src=/js/canvas-nest.js count=80 color=102,255,178 opacity=1></script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>