<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[LR] quEEGNet: QAI for Biosignal Processing | Notes</title>
<meta name=keywords content="Quantum Machine Learning,EEG"><meta name=description content="[This review is intended solely for my personal learning]
Paper Info

arXiv: 2210.00864v1
Title: quEEGNet: Quantum AI for Biosignal Processing
Authors: Toshiaki Koike-Akino, Ye Wang
Prior Knowledge
Biosignal Processing in Human-Machine Interfaces (HMI)
Biosignals such as EEG (electroencephalogram), EMG (electromyogram), and ECoG (electrocorticogram) are fundamental to developing brain-computer interfaces (BCI) and HMIs. However, biosignals are subject to high variability and noise, requiring robust machine-learning models for feature extraction and classification."><meta name=author content><link rel=canonical href=https://HowardHsuuu.github.io/posts/lr/queegnet/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=icon type=image/png sizes=16x16 href=https://HowardHsuuu.github.io/images/icon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://HowardHsuuu.github.io/images/icon-32x32.png><link rel=apple-touch-icon href=https://HowardHsuuu.github.io/images/icon.png><link rel=mask-icon href=https://HowardHsuuu.github.io/images/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://HowardHsuuu.github.io/posts/lr/queegnet/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-...some_hash... crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-...some_hash... crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="[LR] quEEGNet: QAI for Biosignal Processing"><meta property="og:description" content="[This review is intended solely for my personal learning]
Paper Info

arXiv: 2210.00864v1
Title: quEEGNet: Quantum AI for Biosignal Processing
Authors: Toshiaki Koike-Akino, Ye Wang
Prior Knowledge
Biosignal Processing in Human-Machine Interfaces (HMI)
Biosignals such as EEG (electroencephalogram), EMG (electromyogram), and ECoG (electrocorticogram) are fundamental to developing brain-computer interfaces (BCI) and HMIs. However, biosignals are subject to high variability and noise, requiring robust machine-learning models for feature extraction and classification."><meta property="og:type" content="article"><meta property="og:url" content="https://HowardHsuuu.github.io/posts/lr/queegnet/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-11T19:51:02+08:00"><meta property="article:modified_time" content="2025-02-11T19:51:02+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[LR] quEEGNet: QAI for Biosignal Processing"><meta name=twitter:description content="[This review is intended solely for my personal learning]
Paper Info

arXiv: 2210.00864v1
Title: quEEGNet: Quantum AI for Biosignal Processing
Authors: Toshiaki Koike-Akino, Ye Wang
Prior Knowledge
Biosignal Processing in Human-Machine Interfaces (HMI)
Biosignals such as EEG (electroencephalogram), EMG (electromyogram), and ECoG (electrocorticogram) are fundamental to developing brain-computer interfaces (BCI) and HMIs. However, biosignals are subject to high variability and noise, requiring robust machine-learning models for feature extraction and classification."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Topics","item":"https://HowardHsuuu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Literature Review","item":"https://HowardHsuuu.github.io/posts/lr/"},{"@type":"ListItem","position":3,"name":"[LR] quEEGNet: QAI for Biosignal Processing","item":"https://HowardHsuuu.github.io/posts/lr/queegnet/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[LR] quEEGNet: QAI for Biosignal Processing","name":"[LR] quEEGNet: QAI for Biosignal Processing","description":"[This review is intended solely for my personal learning]\nPaper Info\narXiv: 2210.00864v1\nTitle: quEEGNet: Quantum AI for Biosignal Processing\nAuthors: Toshiaki Koike-Akino, Ye Wang\nPrior Knowledge Biosignal Processing in Human-Machine Interfaces (HMI) Biosignals such as EEG (electroencephalogram), EMG (electromyogram), and ECoG (electrocorticogram) are fundamental to developing brain-computer interfaces (BCI) and HMIs. However, biosignals are subject to high variability and noise, requiring robust machine-learning models for feature extraction and classification.\n","keywords":["Quantum Machine Learning","EEG"],"articleBody":"[This review is intended solely for my personal learning]\nPaper Info\narXiv: 2210.00864v1\nTitle: quEEGNet: Quantum AI for Biosignal Processing\nAuthors: Toshiaki Koike-Akino, Ye Wang\nPrior Knowledge Biosignal Processing in Human-Machine Interfaces (HMI) Biosignals such as EEG (electroencephalogram), EMG (electromyogram), and ECoG (electrocorticogram) are fundamental to developing brain-computer interfaces (BCI) and HMIs. However, biosignals are subject to high variability and noise, requiring robust machine-learning models for feature extraction and classification.\nChallenges in Biosignal Processing High inter-subject variability necessitates frequent recalibration. Computational inefficiency of deep learning models in resource-constrained environments. Scalability and generalization remain concerns in BCI applications. Goal The paper introduces a hybrid quantum-classical deep learning model called quEEGNet, which integrates a variational quantum circuit (VQC) into a deep neural network (DNN) for biosignal analysis. The key objectives are:\nDemonstrating quantum-enhanced feature extraction for EEG, EMG, and ECoG. Reducing the number of trainable parameters while maintaining high classification accuracy. Providing a proof-of-concept study showcasing quantum computing’s applicability in HMI/BCI. Method Quantum Artificial Intelligence (QAI) Framework Quantum Neural Network (QNN) Architecture:\nThe model integrates VQC-based feature extraction into a classical DNN. A hybrid training strategy is used where VQC layers are optimized alongside DNN layers. Variational Quantum Circuit (VQC) Design:\nEmploys Pauli-Y rotations and controlled-Z entanglement layers for quantum state evolution. Uses Simplified 2-Design (S2D) ansatz to mitigate barren plateau issues. Hybrid Quantum-Classical Processing:\nEEG/EMG/ECoG signals are preprocessed and embedded into quantum states. QNN performs feature transformation before passing the output to EEGNet, a well-known deep learning model for biosignal classification. Experimental Setup Datasets: Multiple publicly available physiological datasets (EEG, EMG, ECoG) were used for evaluation. Baseline Comparison: The model is benchmarked against EEGNet, a classical convolutional neural network. Training Details: Optimized using Adam optimizer with a learning rate of 0.1. Implemented using PennyLane and PyTorch. Quantum circuits simulated due to current hardware constraints. Results Dataset EEGNet Accuracy (%) quEEGNet Accuracy (%) Stress 85.87 87.23 RSVP 93.73 95.12 MI 59.61 60.22 ErrP 74.36 75.92 Faces Basic 63.30 64.92 Faces Noisy 75.94 78.01 ASL 23.64 25.16 Performance Improvement: quEEGNet outperformed EEGNet across all datasets, demonstrating the effectiveness of quantum-assisted feature extraction. Parameter Efficiency: The model reduces the number of trainable parameters while maintaining competitive performance. Computational Trade-offs: While QNN offers advantages in parameter efficiency, the practical speedup depends on the maturity of quantum hardware. Conclusion The study presents quEEGNet as a pioneering effort in applying quantum AI to biosignal processing. By integrating variational quantum circuits into deep learning models, the approach achieves state-of-the-art performance across multiple datasets while maintaining computational efficiency. This work establishes QML as a viable direction for future BCI and HMI applications.\nLimitations Quantum Hardware Constraints: Experiments were conducted on simulated quantum processors, which may not fully reflect real-world hardware performance. The practical deployment of quEEGNet depends on advancements in near-term quantum computing. Scalability: While the hybrid model reduces parameter count, the benefits of QNNs over classical DNNs are not yet definitive. Further optimization, such as AutoQML, is necessary to enhance generalization. Limited Variants of QNN: Only one type of VQC architecture was explored. Future work should investigate alternative quantum ansatz and hybrid architectures. References The paper: https://arxiv.org/abs/2210.00864 This review was written with the assistance of Generative AI and is based on the content and results presented in the original paper. ","wordCount":"542","inLanguage":"en-us","datePublished":"2025-02-11T19:51:02+08:00","dateModified":"2025-02-11T19:51:02+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://HowardHsuuu.github.io/posts/lr/queegnet/"},"publisher":{"@type":"Organization","name":"Notes","logo":{"@type":"ImageObject","url":"https://HowardHsuuu.github.io/images/icon.png"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://HowardHsuuu.github.io/ accesskey=h title="Notes (Alt + H)"><img src=https://HowardHsuuu.github.io/images/icon.png alt aria-label=logo height=35>Notes</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://HowardHsuuu.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://HowardHsuuu.github.io/posts/ title=Topics><span>Topics</span></a></li><li><a href=https://HowardHsuuu.github.io/tags title=Tags><span>Tags</span></a></li><li><a href=https://HowardHsuuu.github.io/aboutme/ title="About Me"><span>About Me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://HowardHsuuu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/>Topics</a>&nbsp;»&nbsp;<a href=https://HowardHsuuu.github.io/posts/lr/>Literature Review</a></div><h1 class="post-title entry-hint-parent">[LR] quEEGNet: QAI for Biosignal Processing</h1><div class=post-meta><span title='2025-02-11 19:51:02 +0800 +0800'>February 11, 2025</span>&nbsp;·&nbsp;3 min</div></header><div class=post-content><p>[This review is intended solely for my personal learning]</p><p>Paper Info</p><blockquote><p>arXiv: 2210.00864v1<br>Title: quEEGNet: Quantum AI for Biosignal Processing<br>Authors: Toshiaki Koike-Akino, Ye Wang</p></blockquote><h2 id=prior-knowledge>Prior Knowledge<a hidden class=anchor aria-hidden=true href=#prior-knowledge>#</a></h2><h3 id=biosignal-processing-in-human-machine-interfaces-hmi><strong>Biosignal Processing in Human-Machine Interfaces (HMI)</strong><a hidden class=anchor aria-hidden=true href=#biosignal-processing-in-human-machine-interfaces-hmi>#</a></h3><p>Biosignals such as EEG (electroencephalogram), EMG (electromyogram), and ECoG (electrocorticogram) are fundamental to developing brain-computer interfaces (BCI) and HMIs. However, biosignals are subject to high variability and noise, requiring robust machine-learning models for feature extraction and classification.</p><h3 id=challenges-in-biosignal-processing><strong>Challenges in Biosignal Processing</strong><a hidden class=anchor aria-hidden=true href=#challenges-in-biosignal-processing>#</a></h3><ul><li><strong>High inter-subject variability</strong> necessitates frequent recalibration.</li><li><strong>Computational inefficiency</strong> of deep learning models in resource-constrained environments.</li><li><strong>Scalability and generalization</strong> remain concerns in BCI applications.</li></ul><h2 id=goal>Goal<a hidden class=anchor aria-hidden=true href=#goal>#</a></h2><p>The paper introduces a <strong>hybrid quantum-classical deep learning model</strong> called <strong>quEEGNet</strong>, which integrates a variational quantum circuit (VQC) into a deep neural network (DNN) for biosignal analysis. The key objectives are:</p><ol><li>Demonstrating <strong>quantum-enhanced feature extraction</strong> for EEG, EMG, and ECoG.</li><li><strong>Reducing the number of trainable parameters</strong> while maintaining high classification accuracy.</li><li>Providing a <strong>proof-of-concept study</strong> showcasing quantum computing’s applicability in HMI/BCI.</li></ol><h2 id=method>Method<a hidden class=anchor aria-hidden=true href=#method>#</a></h2><h3 id=quantum-artificial-intelligence-qai-framework><strong>Quantum Artificial Intelligence (QAI) Framework</strong><a hidden class=anchor aria-hidden=true href=#quantum-artificial-intelligence-qai-framework>#</a></h3><ol><li><p><strong>Quantum Neural Network (QNN) Architecture</strong>:</p><ul><li>The model integrates <strong>VQC-based feature extraction</strong> into a classical DNN.</li><li>A <strong>hybrid training strategy</strong> is used where VQC layers are optimized alongside DNN layers.</li></ul></li><li><p><strong>Variational Quantum Circuit (VQC) Design</strong>:</p><ul><li>Employs <strong>Pauli-Y rotations</strong> and <strong>controlled-Z entanglement layers</strong> for quantum state evolution.</li><li>Uses <strong>Simplified 2-Design (S2D) ansatz</strong> to mitigate barren plateau issues.</li></ul></li><li><p><strong>Hybrid Quantum-Classical Processing</strong>:</p><ul><li>EEG/EMG/ECoG signals are preprocessed and embedded into quantum states.</li><li>QNN performs feature transformation before passing the output to EEGNet, a well-known deep learning model for biosignal classification.</li></ul></li></ol><h3 id=experimental-setup><strong>Experimental Setup</strong><a hidden class=anchor aria-hidden=true href=#experimental-setup>#</a></h3><ul><li><strong>Datasets</strong>: Multiple publicly available physiological datasets (EEG, EMG, ECoG) were used for evaluation.</li><li><strong>Baseline Comparison</strong>: The model is benchmarked against <strong>EEGNet</strong>, a classical convolutional neural network.</li><li><strong>Training Details</strong>:<ul><li>Optimized using <strong>Adam optimizer</strong> with a learning rate of 0.1.</li><li>Implemented using <strong>PennyLane</strong> and <strong>PyTorch</strong>.</li><li>Quantum circuits simulated due to current hardware constraints.</li></ul></li></ul><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><table><thead><tr><th><strong>Dataset</strong></th><th><strong>EEGNet Accuracy (%)</strong></th><th><strong>quEEGNet Accuracy (%)</strong></th></tr></thead><tbody><tr><td>Stress</td><td>85.87</td><td><strong>87.23</strong></td></tr><tr><td>RSVP</td><td>93.73</td><td><strong>95.12</strong></td></tr><tr><td>MI</td><td>59.61</td><td><strong>60.22</strong></td></tr><tr><td>ErrP</td><td>74.36</td><td><strong>75.92</strong></td></tr><tr><td>Faces Basic</td><td>63.30</td><td><strong>64.92</strong></td></tr><tr><td>Faces Noisy</td><td>75.94</td><td><strong>78.01</strong></td></tr><tr><td>ASL</td><td>23.64</td><td><strong>25.16</strong></td></tr></tbody></table><ul><li><strong>Performance Improvement</strong>: quEEGNet outperformed EEGNet across all datasets, demonstrating the effectiveness of quantum-assisted feature extraction.</li><li><strong>Parameter Efficiency</strong>: The model <strong>reduces the number of trainable parameters</strong> while maintaining competitive performance.</li><li><strong>Computational Trade-offs</strong>: While QNN offers advantages in parameter efficiency, the practical speedup depends on the maturity of quantum hardware.</li></ul><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>The study presents <strong>quEEGNet</strong> as a pioneering effort in applying <strong>quantum AI to biosignal processing</strong>. By integrating <strong>variational quantum circuits into deep learning models</strong>, the approach achieves <strong>state-of-the-art performance</strong> across multiple datasets while maintaining computational efficiency. This work establishes <strong>QML as a viable direction for future BCI and HMI applications</strong>.</p><h2 id=limitations>Limitations<a hidden class=anchor aria-hidden=true href=#limitations>#</a></h2><ol><li><strong>Quantum Hardware Constraints</strong>:<ul><li>Experiments were conducted on <strong>simulated quantum processors</strong>, which may not fully reflect real-world hardware performance.</li><li>The practical deployment of quEEGNet depends on advancements in <strong>near-term quantum computing</strong>.</li></ul></li><li><strong>Scalability</strong>:<ul><li>While the hybrid model <strong>reduces parameter count</strong>, the benefits of QNNs over classical DNNs are <strong>not yet definitive</strong>.</li><li>Further optimization, such as <strong>AutoQML</strong>, is necessary to enhance generalization.</li></ul></li><li><strong>Limited Variants of QNN</strong>:<ul><li>Only one type of VQC architecture was explored.</li><li>Future work should investigate alternative quantum ansatz and hybrid architectures.</li></ul></li></ol><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ul><li>The paper: <a href=https://arxiv.org/abs/2210.00864>https://arxiv.org/abs/2210.00864</a></li><li>This review was written with the assistance of Generative AI and is based on the content and results presented in the original paper.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://HowardHsuuu.github.io/tags/quantum-machine-learning/>Quantum Machine Learning</a></li><li><a href=https://HowardHsuuu.github.io/tags/eeg/>EEG</a></li></ul><nav class=paginav><a class=prev href=https://HowardHsuuu.github.io/posts/lr/eeg-emotion-recognition/><span class=title>«</span><br><span>[LR] Swarm Intelligence for EEG Channel Selection in Emotion Recognition</span>
</a><a class=next href=https://HowardHsuuu.github.io/posts/lr/flatland-fallacy/><span class=title>»</span><br><span>[LR] The Flatland Fallacy</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://HowardHsuuu.github.io/>Notes</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script type=text/javascript src=/js/canvas-nest.js count=80 color=102,255,178 opacity=1></script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>